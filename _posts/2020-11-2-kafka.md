---
date: 2021-02-17
title: kafka
author: 南夕
---



##### kafka简介

kafka是一个分布式消息队列：生产者、消费者的功能。  

kafka对消息保存时根据Topic进行归类，发送消息者称为Producer,消息接受者称为Consumer，此外kafka集群有多个kafka实例组成，每个实例称为broker，无论kafka集群，还是producer和consumer都依赖于zookeep集群保存一些meta信息，保证系统可用性。

Producer：消息生产者，产生的消息会被发送到某个topic

Consumer：消息消费者，消费的消息内容来自某个topic

Topic：消息根据topic进行归类，topic其本质是一个目录，即将同一主题消息归类到同一个目录

Broke：每一个kafka实例（或者说每台kafka服务器节点）就是一个broker，一个broker可以有多个topic

Partition：每个topic可以有一个或多个partition，分区是在物理层面上的，不同的分区对应不同的数据文件，**kafka使用分区支持物理上的并发写入和读取，从而大大提升了吞吐量**

  Zookeeper：zookeeper集群不属于kafka内的组件，但kafka依赖zookeeper集群保存meta信息

#####   kafka数据处理步骤

Producer产生消息，发送到Broker中

Leader状态的Broker接收消息，写入到相应topic

Leader状态的Broker接收完毕以后，传给Follow状态的Broker作为副本备份

Consumer消费Broker中的数据

##### Kafka核心概念

- Topic（主题）

每一条发送到kafka集群的消息都可以有一个类别，这个类别叫做topic，不同的消息会进行分开存储，如果topic很大，可以分布到多个broker上，topic被认为是一个队列，每一条消息都必须指定它的topic，可以说我们需要明确把消息放入哪一个队列。kafka集群会保留所有的消息，无论被消费与否，提供两种策略删除旧数据：基于时间，基于Partition文件大小。

- Broker（代理）

一台kafka服务器就可以称为broker，一个集群由多个broker组成，一个broker可以有多个topic

- Partition

为了使kafka吞吐量线性提高，物理上把topic分为一个或多个分区，每一个分区是一个有序的队列，且每一个分区在物理上都对应这一个文件夹，该文件夹下存储着这个分区所有消息和索引文件。

- Replicas（副本）

一旦某一个Broker宕机，则其上所有的Partition数据都不可被消费，所以需要对分区备份，其中一个宕机后，其它Replica必须要能继续服务并且不能造成数据重复也不能造成数据丢失

Replicas的一致性问题：每个Partition有多个副本，其中有且仅有一个作为Leader，Leader负责数据读写，Follower只向Leader顺序Fetch数据

如果leader失效，则从Follower中选举一个新的leader

当follower挂掉、卡住或太慢，leader会把这个follower删除，重新创建一个Follower

备份数设置为N，表示主+备=N

- Consumer Group

每个Consumer属于一个特定的Consumer Group

将多个消费者集中到一起去处理某一个Topic的数据，可以更快的提高数据消费的能力

整个消费者共享一组偏移量，因为一个Topic有多个分区

- 偏移量

偏移量决定读取数据的位置，不会有线程安全的问题，消费者通过偏移量来决定下次读取的消息

消息被消费之后，并不会马上被删除，这样一个业务就可以重复使用kafka的消息

可以通过修改偏移量达到重新读取消息的目的，偏移量由用户控制

消息最终还是会被删除，默认生命周期为1周



![image-20211027153555807](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20211027153603.png)









