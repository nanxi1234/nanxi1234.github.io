---
title: JUC
---



###### 并发简述

如果多个线程访问同一个可变的状态变量时没有使用合适的同步。那么程序就会出现错误，解决方案：

- 不在线程之间共享该状态变量
- 将状态变量修改为不可变的变量
- 在访问状态变量时采用同步

###### 有哪些对象一定是线程安全的

无状态对象：既不包含任何域，也不包含任何对其他类中域的引用，由于线程访问无状态对象时不会影响其他线程，因此无状态对象是线程安全的。

不可变对象：如String之类的，由于它无法被线程改变，因此它是线程安全的。

###### 如何保持一致性

要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。

###### 内置锁

每个java对象都可以用作一个实现同步的锁，这些锁称为内置锁，Java的内置锁相当于一种互斥锁，最多只有一个线程能持有这种锁，互斥锁会导致性能降低，因为同一时刻只有一个线程能执行加锁的代码。

为什么每个对象都有一个内置锁？

**对于可能被多个线程同时访问的可变状态变量，在访问它时都需要持有同一个锁。之所以每个对象都有一个内置锁，只是为了免去显式地创建锁对象**。

###### 内存可见性

我们不希望某个线程正在使用对象状态而另外一个线程同时在修改状态，而是希望确保某个线程修改了对象状态后，其他线程能够看到发生的状态变化。

###### 非原子的64位操作

对于非Volatile类型的long和double变量，JVM允许将64位的读操作或写操作分解为两个32位操作，在多线程程序中使用共享且可变的long、double等类型的变量也是不安全的，除非用volatile来声明它们，或者用锁保护。

###### 加锁的含义

加锁的含义不仅仅局限于互斥行为，还包括内存可见性，为了确保所有线程都能看到共享变量的最新值，所有执行读或者写的线程都必须在同一个锁上同步。

###### 讲一讲Volatile

一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：

　　1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。

　　2）禁止进行指令重排序。

- Volatile只能保证可见性，无法保证原子性

- Volatile的原理和实现机制

加入Volatile关键字时，会多出一个lock前缀指令，相当于一个内存屏障，内存屏障会提供3个功能：

- 确保指令重排序时不会将其后面的指令排到内存屏障之前的位置，也不会将前面的指令排到内存屏障的后面。
- 强制将对缓存的修改操作立即写入主存
- 如果是写操作，会导致其它cpu中对应的缓存行无效

##### Synchronized的实现原理

###### 对象头

![img](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210912154854.png)

当线程访问同步块时首先需要获得锁并把相关信息存储在对象头中。

mark word：存放HashCode、GC分代年龄、锁状态标记、线程持有的锁、偏向线程ID、偏向时间戳等，synchronized源码就是用它来标识对象的加锁状态。

klass pointer：对象指向它的类元数据的指针。

###### Monitor

Monitor是线程私有的数据结构，叫做内置锁，每一个线程都有一个可用的monitor列表，同时还有一个全局的可用列表，每一个被锁住的对象都会与一个monitor关联（对象头的MarkWord中的LockWord指向monitor的起始地址），同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。

**实现原理**：

synchronized关键字经过Javac编译后，会在同步块前后分别形成monitorenter和monitorexit这两个字节码指令。这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象，如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作为reference。如果没有明确指定，那就将根据它所修饰的方法类型，来决定是取代码所在对象的实例还是取类型对应的Class对象来作为线程要持有的锁。在执行monitorenter指令时，首先要去尝试获取对象的锁，如果对象没被锁定，或者当前线程已经持有那个对象的锁，就把锁的计数器的值加一，在执行monitorexit指令时会将锁计数器的值减一，一旦计数器的值为0，所就被释放了，如果获取锁失败，当前线程就会被阻塞直到锁释放为止。

缺点：synchronized同步块对同一线程来说是可重入的，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入，由于Java线程是映射到操作系统中的原本线程中的，如果要阻塞或者唤醒一个线程，都需要操作系统来帮忙，这就需要从用户态切换到核心态，耗费CPU和时间，所以Synchronized是重量级的操作。但是虚拟机本身也做了大量的优化，如无锁、偏向锁、轻量级锁、重量级锁。

###### Synchronized和volatile的区别

- volatile只能作用于变量，而synchronized可以作用于**变量、方法块和代码块**
- 多线程访问volatile时不会发生阻塞，而snychronized会发生阻塞
- volatile能够保证数据的可见性，但是无法保证原子性，而snychronized两者均可保证
- 综上，volatile主要是解决了多个线程之间的可见性，而synchronized主要是保证多个线程访问资源的同步性。

##### 什么是线程、进程、协程

###### 进程

进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是**系统进行资源分配和调度的基本单位**，是[操作系统](http://baike.baidu.com/view/880.htm)结构的基础。在早期面向进程设计的计算机结构中，进程是程序的基本执行实体；在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。

　　进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的[代码](http://baike.baidu.com/view/41.htm)，还包括当前的活动，通过[程序计数器](http://baike.baidu.com/view/178145.htm)的值和处理[寄存器](http://baike.baidu.com/view/6159.htm)的内容来表示。

　　进程的概念主要有两点：第一，进程是一个实体。**每一个进程都有它自己的地址空间**，一般情况下，包括[文本](http://baike.baidu.com/view/300107.htm)区域（text region）、数据区域（data region）和[堆栈](http://baike.baidu.com/view/93201.htm)（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。第二，进程是一个“执行中的程序”。程序是一个没有生命的实体，只有[处理](http://baike.baidu.com/view/989420.htm)器赋予程序生命时（操作系统执行时），它才能成为一个活动的实体，我们称其为[进程](http://baike.baidu.com/view/19746.htm)。

进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。**由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。**

###### 线程

**线程是进程的一个实体,是CPU调度和分派的基本单位**,它是比进程更小的能独立运行的基本单位.**线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)**,但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。

一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程 在运行中呈现出间断性。线程也有[就绪](http://baike.baidu.com/view/654230.htm)、[阻塞](http://baike.baidu.com/view/497285.htm)和[运行](http://baike.baidu.com/view/1026025.htm)三种基本状态。就绪状态是指线程具备运行的所有条件，逻辑上可以运行，在等待处理机；运行状态是指线程占有处理机正在运行；阻塞状态是指线程在等待一个事件（如某个信号量），逻辑上不可执行。每一个程序都至少有一个线程，若程序只有一个线程，那就是程序本身。

线程是程序中一个单一的顺序控制流程。进程内一个相对独立的、可调度的执行单元，是系统独立调度和分派CPU的基本单位指[运行](http://baike.baidu.com/view/1026025.htm)中的程序的调度单位。在单个程序中同时运行多个线程完成不同的工作，称为[多线程](http://baike.baidu.com/view/65706.htm)。

###### 协程

**协程是一种用户态的轻量级线程，**协程的调度完全由**用户控制**。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。**协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程**，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。

###### 线程和进程的区别

- 资源开销

  每个进程都有独立的代码和程序上下文，程序上下文之间的切换会有较大的开销，线程可以看作轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立运行栈和程序计数器，线程之间切换的开销小。

- 包含关系

  线程是进程的一部分

- 内存分配

  同一进程的线程共享本进程的地址空间和资源，而进程与进程之间的地址空间和资源是相互独立的

- 影响关系

  一个进程崩溃后，在保护模式下不会对其它进程产生影响，但是线程崩溃有可能导致整个进程都死掉，所以多进程要比多线程健壮

- 执行过程

  每个独立的进程有程序运行的入口、顺序执行序列和程序出口，但是线程不能独立执行。

###### 进程PCB

- 作用

![image-20190701203253244](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210928212354.png)

- 进程配置了PCB之后才能获取OS服务
- 保存进程暂停的CPU现场信息，进程再次被调度时恢复进程的CPU现场信息
- OS根据PCB的内容对进程进行管理,因为PCB反应了进程的状态
- 只有处于就绪状态的进程才能被调度，OS通过PCB知道了进程的状态并根据PCB中的信息决定调度策略
- PCB中具有实现进程通信的区域或通信队列指针等

PCB中的信息

![image-20190701204551632](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210928212847.png)

###### 线程的状态

- 新建(NEW)：新创建了一个线程对象

- 就绪(RUNNABLE)：线程对象创建后，当调用线程对象的star()方法，该线程处于就绪状态，等待被线程调度选中，获取cpu的使用权。

- 阻塞(BLOCKED)：处于运行状态中的线程由于某种原因，暂时放弃对CPU的使用权，停止执行。

  阻塞分三种：

  - 等待阻塞：运行状态中的线程执行wait()方法，JVM会把该线程放入到等待队列
  - 同步阻塞：线程在获取synchronized同步锁失败，则JVM会把线程放入锁池中，线程进入同步阻塞状态。
  - 其他阻塞：通过调用线程的sleep()或者join()或发出I/O请求时，线程会进入到阻塞状态，当sleep()、join()、或者I/O请求完成后，线程重新转入就绪状态。

- 等待(WAITING):不会被CPU分配时间，要等待被显式地唤醒，否则一直等。（一直等）

- 超时等待(TIMED_WAITING):在指定的时间后自行返回

- 终止(TERMINATED)：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期

wait/sleep的区别？

wait：Object

sleep：Thread

锁的释放：wait会释放锁，sleep不释放锁

适用范围：wait必须在同步代码块中；sleep可以在任何地方用

###### 什么是线程安全

目前主流操作系统都是多任务的，即多个进程同时运行。为了保证安全，每个进程只能访问分配给自己的内存空间，而不能访问别的进程的，这是由操作系统保障的。在每个进程的内存空间中都会有一块特殊的公共区域，通常称为堆（内存）。进程内的所有线程都可以访问到该区域，这就是造成问题的潜在原因。

所以线程安全指的是，在堆内存中的数据由于可以被任何线程访问到，在没有限制的情况下存在被意外修改的风险。即堆内存空间在没有保护机制的情况下，对多线程来说是不安全的地方，因为你放进去的数据，可能被别的线程“破坏”。

###### 线程一定能提高效率吗？

不一定，**一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间。三是线程之间如果频繁争用数据，互相阻塞甚至死锁，将会大大降低程序的并发能力。**

###### 进程的通讯方式

- 管道

  管道的通知机制类似于缓存，一个进程把数据放在某个缓存区域，然后等着另一个进程去拿，并且管道是单向传输的。

  缺点是：效率太低，a进程给b进程传输数据，只能等待b取了数据之后，a才能返回。

  优点：简单，可靠

  管道分为：

  匿名管道：半双工，单向，只能在具有亲缘关系的进程间使用

  命名管道：可以不相关的进程中相互通信

- 消息队列

  a给b发送消息，只需要把消息放在消息队列里就行了，b需要时再去取。

  缺点：如果发送的数据很大，需要花费时间来拷贝。

- 共享内存

  共享内存可以很好地解决拷贝所消耗的时间，系统加载一个进程时，分配给进程的内存实际上并不是实际物理内存，而是虚拟内存空间。如果让两个进程各自拿出一块虚拟空间，然后映射到相同的物理内存中，实现共享。

- 信号量

  共享内存的缺点是进程竞争内存的问题，信号量的本质是一个计数器，用来实现进程之间的互斥与同步，比如信号量的初始值是1，然后a进程来访问内存的时候将值置为0，b来访问的时候，看到值为0就知道有进程在访问内存，b将无法访问这部分内存。

- Socket

  不仅可以用于相同主机上的进程间通信，也可以用于两个相隔很远的进程通信。

  可，

  - 实现TCP字节流通信
  - 实现UDP数据库通信
  - 实现本地进程间的通信

- 信号

  对于异常状态下的工作模式，需要用信号的方式来通知进程，在Linux操作系统中，为了响应各种各样的事件，提供了几十种信号

  <center><img src="https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210916182852.png" alt="image-20210916182845303" style="zoom:67%;" /></center>

运行在shell终端时，可以通过键盘输入某些组合键的时候，给进程发送信号：

例如，进程在后台运行，可以通过kill命令的方式给进程发信号，但前提是需要知道运行中的进程PID号，例如：

- kill -9 1050,表示给PID为1050的进程发送SIGKILL信号，用来立即结束该进程。

信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一个进程。

#### 说一说你知道的锁

##### 悲观锁&&乐观锁

- 悲观锁

对于同一个数据的并发操作，悲观锁认为自己在使用数据时一定有别的线程来修改数据，因此在获取数据时会先加锁，确保数据不会被别的线程修改。java中Synchronized关键字和Lock的实现类都是悲观锁。

- 乐观锁

乐观锁认为在自己使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据，如果这个数据没有被更新，当前线程将自己修改的数据成功写入，如果已更新，则根据不同的实现方式执行不同的操作（报错或者自动重试）。

使用场景：乐观锁适用于读操作比较多的场景，多写的场景下用悲观锁比较合适。

###### 乐观锁是如何实现的？

通过无锁编程来实现，最常用的是CAS算法，Java中原子类的递增操作就是通过CAS自旋实现的。

###### 什么是CAS?

Compare and swap,是一种无锁算法，在不使用锁的情况下实现线程之间的变量同步。CAS 是实现自旋锁的基础，CAS 利用 CPU 指令保证了操作的原子性，以达到锁的效果，至于自旋呢，看字面意思也很明白，自己旋转，翻译成人话就是循环，一般是用一个无限循环实现。这样一来，一个无限循环中，执行一个 CAS 操作，当操作成功，返回 true 时，循环结束；当返回 false 时，接着执行循环，继续尝试 CAS 操作，直到返回 true。

CAS算法涉及到的三个操作数:

- 需要读写的内存值

- 需要比较的值A

- 要写入的新值B

当且仅当V的值等于A时，CAS通过原子方式用新值B来更新V的值（“比较+更新整体是一个原子操作”），否者不会进行任何操作，一般情况下，更新是一个不断重试的操作。

###### CAS存在的问题

- ABA问题

CAS需要在操作值时的时候检查内存值是否发生变化，没有变化才会更新，但是如果内存值是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没发生变化，但是实际上是有变化的，ABA的解决方法是在变量前面添加版本号，每次更新的时候都把版本号加一。

- 循环时间长开销大

CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销

- 只能保证一个共享变量的原子操作

对一个变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS无法保证操作的原子性。

java从1.5开始JDK提供AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。

##### 自旋锁&&适应性自旋锁

阻塞或唤醒一个java线程需要操作系统切换CPU状态来完成，这种状态的切换需要耗费处理器较长的时间，在许多场景下，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。为了解决这种问题，我们让线程自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不用阻塞而是直接获取同步资源，从而避免了线程切换的开销，这就叫做自旋锁。

自旋锁本身的问题很明显，它虽然避免了线程切换的开销，但是要占用处理器的时间，如果锁被占用的时间很长，那么自旋的线程会白白浪费处理器资源，因此自旋时间要设定一个限度，超过限度没有成功获得锁，就应当挂起线程。

通过对自旋时间设定限值能够避免锁的长时间自旋，但是如果设定的是一个定值，会出现刚放弃自旋，没过多久锁就被释放了，这样之前就白等了。为了解决这个问题，JDK6中引入了自适应的自旋锁。

自适应自旋锁是一种根据历史情况来决定自旋时间的锁，如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋很有可能再次成功，进而允许自旋等待持续相对较长的时间，如果对于某个锁，自旋很少成功获得过，那么以后尝试获取这个锁时将省略自旋过程，直接阻塞线程，避免浪费处理器资源

##### Synchronized锁优化：无锁&&偏向锁&&轻量级锁&&重量级锁

对象头主要包含两部分数据：Mark Word（标记字段）、Klass Point（类型指针）。

- Mark Word

默认存储对象的HashCode，分代年龄和锁标志位信息。

- Klass Point

对象指向它的类元数据指针，虚拟机通过这个指针来确定这个对象是哪个类的实例

这四种锁是指锁的状态，专门针对synchronized的

为什么Synchronized能实现线程同步？

synchronized通过Monitor来实现同步，Monitor（内置锁）是依赖底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。JDK6之前的Synchronized之所以效率低，是因为使用的是Mutex Lock，这种依赖于操作系统的锁，我们称之为“重量级锁”，JDK6中为了减少锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。

锁的4种状态：级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁，锁只能升级不能降级。

###### 无锁（01）

无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。线程会不断尝试修改贡献资源，如果没有冲突就修改成功并退出，否则就会继续尝试直至修改成功，CAS就是基于无锁来实现的。

###### 偏向锁

偏向锁是指一段同步代码一直被一个线程所访问，那么线程会自动获取锁，降低获取锁的代价。

在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁，目标是在只有一个线程执行同步代码块时能够提高性能。

当一个线程访问同步块并获取锁时，会在Mark Word里存储锁偏向的线程ID，在线程进入和退出同步块时检测Mark Word里是否存储着指向当前线程的偏向锁，**引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径。轻量级锁的获取和释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可**。

偏向锁的释放，只有遇到其它线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，需要等到没有字节码正在执行时，先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到无锁或轻量级锁的状态。

###### 轻量级锁（00）

是指**锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级成轻量级锁，其他线程会以自旋的形式尝试获取锁，不会阻塞，从而提高性能**。

虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Record)的空间，用于存储对象目前的Mark Word的拷贝，拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。如果更新成功，那么线程就拥有了该对象的锁，并且对象的Mark Word的锁标置位设置为“00”表示此对象处于轻量级锁定状态。如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。

若当前只有一个等待进程，则该进程通过自旋进行等待，但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访问时，轻量级锁升级为重量级锁。

###### 重量级锁

升级为重量级锁时，锁的标志位变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时所有的所都会进入阻塞状态。

综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作，而轻量级锁是通过用CAS操作和自旋来解决加锁问题

有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数（xx：PreBlockSpin）更改）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁

##### 公平锁&&非公平锁

公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁，公平锁的优点是等待锁的线程不会饿死，缺点是整体吞吐率相对非公平要低，等待队列中除第一个线程意外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。

非公平锁是多个线程加锁时直接尝试获取锁，获取不到时才会去队列的队尾等待，但如果此时锁刚好可用，那么这个线程可以直接无需阻塞直接获取到锁，好处是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁CPU不必唤醒所有的线程，缺点是处于等待队列中的线程可能会被饿死或等待很久才能获得锁。

###### 可重入锁&&非可重入锁

可重入锁：某线程的第一个子流程可以获取到锁，该线程的其它子流程也可以获取到这个锁，线程A的多个子流程都能够执行完毕并释放锁，再由其它线程获取锁。

不可重入锁：只有线程的第一个子流程可以获取到锁，该线程的其他子流程无法获取到这个锁，当前线程发生死锁，导致等待队列中的所有线程都无法执行。

###### 独享锁&&共享锁

独享锁只能被一个线程所持有，共享锁是指能被多个线程所持有，共享锁是指该锁可被多个线程所持有，如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排他锁，获得共享锁的线程只能读数据，不能修改数据。



###### 死锁产生条件

- 互斥：线程对于需要的资源进行互斥访问
- 持有并等待：线程持有了资源，同时又在等待其他资源
- 非抢占：线程获得的资源，不能被抢占
- 循环等待：线程之间存在一个环路，环路上的每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的。

这四个条件中的任何一个没有满足，死锁就不会产生。

###### 如何解决死锁问题？

只要破坏任一个条件就可以解决

- 破坏循环等待条件：申请资源时采用有序的方式
- 破坏请求与保持条件：一次性申请所有的资源
- 破坏非抢占条件：线程在申请不到所需资源时，主动放弃所持有的资源

##### JUC简介

###### Lock简介(JUC的核心组件)

{@code Lock} 实现提供了比使用 {@code synchronized} 方法和语句可以获得的更广泛的锁定操作。它们允许更灵活的结构，并且可能支持多个关联的 {@link Condition} 对象。{@code synchronized} 方法或语句的使用提供对与每个对象关联的隐式监视器锁的访问，但强制所有锁获取和释放以块结构方式发生，而{@code Lock} 接口的实现允许在不同范围内获取和释放锁，并允许以任何顺序获取和释放多个锁。

Lock是一个接口，定义了释放锁和获得锁的抽象方法，定义成接口就意味着它定义了锁的一个标准规范，其它的锁可以对它进行不同的实现。

常见锁的实现：

- ReentrantLock：表示重入锁，指线程在获取锁之后，再次获取该锁不需要再阻塞，而是直接关联一次计数器增加重入次数。
- ReentrantWriteLock:重入读写锁，实现了ReadWriteLock接口，这个类中维护了两个锁，一个是ReadLock，一个是WriteLock，他们都分别实现了Lock接口。读写锁适合读多写少，基本原则是：读与读不互斥、读与写互斥、写与写互斥。涉及到影响数据变化的操作都会存在互斥。
- StampedLock：读写锁虽然通过分离读与写的功能使得读与读之间可以完全并发，但是读与写是有冲突的，如果大量的读线程存在，可能就会引起写写线程的饥饿。StampedLock是一种乐观锁，不会阻塞写线程。

###### ReentrantLock重入锁

重入锁的是为了避免线程死锁

在多线程竞争重入锁时，竞争失败的线程是如何实现阻塞以及被唤醒的？

#### AQS

AQS 队列内部维护的是一个 FIFO 的双向链表，这种结构的特点是每个数据结构都有两个指针，分别指向直接的后继节点和直接前驱节点。所以双向链表可以从任意一个节点开始很方便的访问前驱和后继。每个 Node 其实是由线程封装，当线程争抢锁失败后会封装成 Node 加入到 AQS 队列中去；当获取锁的线程释放锁以后，会从队列中唤醒一个阻塞的节点(线程)。

Node所包含的字段：

| waitStatus  |      当前节点在队列中的状态       |
| :---------: | :-------------------------------: |
|   thread    |       表示处于该节点的线程        |
|    prev     |             前驱指针              |
|    next     |             后继指针              |
| predecessor |   返回前驱节点，没有的话抛出npe   |
| nextWaiter  | 指向下一个处于CONDITION状态的节点 |

waitStatus有以下几个枚举值：

```java
指示节点在共享模式下等待的标记
static final Node SHARED = new Node();
指示节点正在以独占模式等待的标记
static final Node EXCLUSIVE = null;
等待状态值：指示线程是否已取消
static final int CANCELLED =  1;
等待状态值：指示后继线程是否要被唤醒的值
static final int SIGNAL    = -1;
等待状态值：指示线程正在等待条件
static final int CONDITION = -2;
指示下一个acquireShared 应无条件传播的waitStatus 值
static final int PROPAGATE = -3;
```

|   枚举    |                    含义                     |
| :-------: | :-----------------------------------------: |
|     0     |        当一个Node被初始化时的默认值         |
| CANCELLED |      1,表示线程获取锁的请求已经取消了       |
| CONDITION |  -2,表示节点在等待队列中，节点线程等待唤醒  |
| PROPAGATE | -3，当线程处于SHARE情况下，该字段才会被使用 |
|  SIGNAL   |  -1，表示线程已经准备好了，就等资源释放了   |

线程两种锁的模式：SHARE/EXCLUSIVE

```java
private volatile int state;
```

- 同步状态State

用于展示当前临界资源的获锁情况

|                  方法名                   |                 描述                 |
| :---------------------------------------: | :----------------------------------: |
|                getState()                 |            获取State的值             |
|          setState(int  newState)          | 设置State的值protected final boolean |
| compareAndSetState(int expect,int update) |         使用CAS方式更新State         |

###### AQS方法与ReentrantLock的关联

|                   方法名                    |                             描述                             |
| :-----------------------------------------: | :----------------------------------------------------------: |
|    protected boolean isHeldExclusively()    |   该线程是否正在独占资源，只有用到Condition才需要去实现它    |
|   protected boolean tryAcquired(int arg)    | 独占方式，arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False |
|    protected boolean tryRelease(int arg)    | 独占方式，arg为释放锁的次数，尝试释放资源。成功则返回True，失败则返回False |
|   protected int tryAcquireShared(int arg)   | 共享方式，arg为获取锁的次数，尝试获取资源，负数表示失败；0表示成功，但是没有剩余可用资源；正数表示成功，且有剩余资源。 |
| protected boolean tryReleaseShared(int arg) | 共享方式，arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待节点返回True，否则返回False。 |

###### 线程如何被加入到等待队列中

当执行Acquired(1)时，会通过tryAcquired获取锁，如果失败就会调用addWaiter加入到等待队列中去。

- 通过当前的线程和锁模式new一个节点
- pred指针指向尾结点

- 将Node的Prev指针指向Pred

- 通过compareAndSetTail方法，完成尾结点的设置，主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为update的值。

![img](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210908164609.png)

总结，线程获取锁的时候，过程大体如下：

- 当没有线程获取到锁时，线程1获取锁成功
- 线程2申请锁，但是锁被线程1占用
- 如果再有线程要获取锁，依次在队列中往后排队即可

hasQueuedPredecessors是公平锁加锁时判断等待队列中是否存在有效节点的方法，如果返回False，说明当前线程可以争共享资源；如果返回True，说明队列中存在有效节点，当前线程必须加入到等待队列中。

双向链表中，第一个节点为虚节点，其实并不存储任何信息，只是占位。真正的第一个有数据的节点，是在第二个节点开始的。

###### 何时出队列，acquireQueued源码分析

```java
/**
 * Acquires in exclusive uninterruptible mode for thread already in
 * queue. Used by condition wait methods as well as acquire.
 *
 * @param node the node
 * @param arg the acquire argument
 * @return {@code true} if interrupted while waiting
 */
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head && tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

```java
/**
 * Checks and updates status for a node that failed to acquire.
 * Returns true if thread should block. This is the main signal
 * control in all acquire loops.  Requires that pred == node.prev.
 *
 * @param pred node's predecessor holding status
 * @param node the node
 * @return {@code true} if thread should block
 */
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)
        /*
         * This node has already set status asking a release
         * to signal it, so it can safely park.
         */
        return true;
    if (ws > 0) {
        /*
         * Predecessor was cancelled. Skip over predecessors and
         * indicate retry.
         */
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus > 0);
        pred.next = node;
    } else {
        /*
         * waitStatus must be 0 or PROPAGATE.  Indicate that we
         * need a signal, but don't park yet.  Caller will need to
         * retry to make sure it cannot acquire before parking.
         */
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}
```

```java
/**
 * Convenience method to park and then check if interrupted
 *
 * @return {@code true} if interrupted
 */
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);
    return Thread.interrupted();
}
```

当前前置节点是头结点，且当前线程获取锁成功

![img](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210908173232.png)



shouldParkAfterFailedAcquire流程：

![img](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210908172331.png)

- shouldParkAfterFailedAcquire中取消节点是怎么生成的？什么时候会把waitStatus设置为-1？
- 什么时候释放节点通知被挂起线程？

###### CANCELLED状态节点生成

```java
/**
 * Cancels an ongoing attempt to acquire.
 *
 * @param node the node
 */
private void cancelAcquire(Node node) {
    // 将无效节点过滤
    if (node == null)
        return;
    //设置节点不关联任何线程，即虚节点
    node.thread = null;

    // 通过前驱节点，跳过取消状态的node
    Node pred = node.prev;
    while (pred.waitStatus > 0)
        node.prev = pred = pred.prev;

    //获取过滤后的前驱节点的后继节点
    Node predNext = pred.next;

    //将当前的node状态设置为CANCELLED
    node.waitStatus = Node.CANCELLED;

    // 如果当前节点是尾节点，将从后往前的的第一个非取消状态的节点设置为尾结点
    //更新失败的话，进入else，更新成功，将tail的后继节点设置为null
    if (node == tail && compareAndSetTail(node, pred)) {
        compareAndSetNext(pred, predNext, null);
    } else {
        // If successor needs signal, try to set pred's next-link
        // so it will get one. Otherwise wake it up to propagate.
        int ws;
        if (pred != head &&
            ((ws = pred.waitStatus) == Node.SIGNAL ||
             (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&
            pred.thread != null) {
            Node next = node.next;
            if (next != null && next.waitStatus <= 0)
                compareAndSetNext(pred, predNext, next);
        } else {
            unparkSuccessor(node);
        }

        node.next = node; // help GC
    }
}
```

- 获取当前节点的前驱节点，如果前驱节点的状态是CANCELLED，那就一直往前遍历，找到第一个waitStatus<=0的节点，将找到的Pred节点和当前Node关联，将当前的Node设置为CANCELLED。

- 根据当前节点的位置，考虑以下三种情况：

  1. 当前节点是尾结点

  ![img](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210908191222.png)

  2. 当前节点是Head的后继节点

  ![img](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210908191335.png)

  3. 当前节点不是Head的后继节点，也不是尾结点

![img](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210908193835.png)

- 为什么只对next指针进行操作，不对Prev指针进行操作？什么情况下会对Prev操作？



##### AQS面试题总结

- 什么是AQS？

  AQS是队列同步器AbstractQueuedSynchronizer的简写，用于构建锁和其他同步组件的基础框架，通过内置的先进先出队列来完成资源竞争排队的工作。

- AQS中采用了哪些设计模式？

  模板方法模式

- AQS中提供了哪些模板方法?

  |      方法       |                           方法说明                           |
  | :-------------: | :----------------------------------------------------------: |
  |   Acquired()    | 独占锁获取同步状态，如果当前线程获取同步状态成功，则该方法返回，否则，进入同步队列等待，该方法将会调用重写的tryAcquired()方法 |
  | AquiredShared() |    获取共享锁，如果没有获取到共享锁，则会进入同步等待队列    |
  |    release()    | 释放同步状态，并通知同步器，唤醒等待队列中第一个节点中包含的线程 |
  |  releaseShare   |                         释放同步状态                         |

  

- 如何修改和访问同步器的状态？

getState：获取当前同步状态

setState：设置当前同步状态

compareAndSetState：使用CAS设置当前状态，该方法能保证状态设置的原子性。

这三个也是模板方法

- 如何精准地唤醒线程?

  我们总结下 Condition 和 wait/notify 的比较：

  - Condition 可以精准的对多个不同条件进行控制，wait/notify 只能和 synchronized 关键字一起使用，并且只能唤醒一个或者全部的等待队列；
  - Condition 需要使用 Lock 进行控制，使用的时候要注意 lock() 后及时的 unlock()，Condition 有类似于 await 的机制，因此不会产生加锁方式而产生的死锁出现，同时底层实现的是 park/unpark 的机制，因此也不会产生先唤醒再挂起的死锁，一句话就是不会产生死锁，但是 wait/notify 会产生先唤醒再挂起的死锁。

- 说一说AQS中的同步队列的数据结构

  1. 当前线程获取同步状态失败，同步器将当前线程及等待状态等信息构成一个Node节点加入队列，放在队尾，同步器重新设置尾结点。
  2. 加入队列后，会阻塞当前线程。
  3. 同步状态被释放并且同步器从新设置首节点，同步器唤醒等待队列中的第一个节点，让其再次获取同步状态。

  继续讲设置首尾节点时的线程安全问题：

  当多个线程同一时刻去获取同步状态(独占锁)时，肯定只会有一个线程竞争成功，其他线程都会被放到等待队列的末尾，当多个线程同时被塞到队列末尾时，就相当于同时竞争末尾这个资源，这时候就会出现线程安全问题。

  为了保证设置队尾元素线程的安全，同步器提供了compareAndSetTail(Node expecr,Node update)方法（依赖于native方法），传入当前线程认为的尾结点和当前要设置成尾结点的节点，只有设置成功，才将当前节点正式与之前的尾结点关联。

- 设置首节点时，是不是也要用CAS来保证线程安全？

  不是，首先设置尾结点时是因为存在多个线程同时竞争所以才需要CAS保证线程安全性，但是释放同步状态设置头节点时，只有获取到同步状态的线程才能设置，由于能获取独占锁状态的线程只有一个，因此不会发生线程安全性的问题，所以不需要CAS。

- 独占式同步状态的获取与释放？

  - 当前线程调用自定义同步器实现的**tryAcquire**方法，该方法保证线程安全的获取同步状态，如果**同步状态获取失败**，则执行后续流程
  - 构造独占式同步节点，通过调用**addWaiter**方法将Node塞入**同步队列尾部**，并且调用**acquireQueued**方法自旋获取同步锁状态，如果获取不到，则**阻塞**当前线程。
  - addwaiter()的细节：如果尾节点不为空则快速尝试在尾部添加，若添加失败或尾结点为空则调用enq采用自旋的方式来设置尾节点

  - acquiredQueued()：使用自旋的方式获取同步状态，并且只有当前节点的前驱节点是头结点时，才会调用tryAcquired获取同步状态，否则继续自旋。为什么需要前驱节点是头结点？因为当拥有同步状态的线程释放同步状态时，会唤醒其后继节点，为了维护FIFO原则，其后继节点被唤醒后就需要检查自己的前驱节点是不是头结点，这样才能保证FIFO原则。

  

  ![sqwhqu5wsr](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210910195617.png)

- 说说独占锁和共享锁在AQS实现代码上的区别

区别1：共享锁是可以被多个线程同时拥有的，并且获取同步状态是否成功，共享锁主要是判断返回值是否大于0，而独占锁是通过true或false来判断。

区别2：独占锁在释放同步状态时不用关心线程安全的问题，因为只有一个线程在释放同步状态，但是共享锁是被多个线程同时拥有，所以释放同步状态时需要保证线程安全，一般通过CAS+自旋来实现。

#### 线程池

##### 基本概念

线程池主要是控制运行线程的数量，将待处理任务放到等待队列，然后创建线程执行这些任务，如果超过了最大线程数，则等待其他线程执行完毕，再从队列中取出任务执行。

为什么使用线程池？

现在是多核电脑，多个线程各自跑在自己的CPU上，不用切换效率高

优点：

- 线程复用：不用一直new线程，重复利用已经创建的线程来降低线程的创建和销毁开销，节省系统资源。（用完回到线程池给其他任务用）

- 提高响应速度，不是每次都需要创建新的线程
- 管理线程：可以控制最大并发数，控制线程的创建等

核心类：Executor→ExecutorService→AbstractExecutorService→ThreadPoolExecutor是线程创建的核心类。

| Excutors.newFixedThreadPool(int)  |         一池固定数量的线程，超出的线程需要在队列中等待，内部的corePoolSize和maxmumPoolSize的值是相等的，使用LinkedBlocking队列，执行长期任务，性能会很好         |
| :-------------------------------: | :----------------------------------------------------------: |
| Excutors.newScheduledThreadPool(int) | 创建一个固定数量的线程池，相比于newFixedThreadPool(int)固定个数的线程池可以：执行延时任务，执行带有返回值的任务，使用的是DalayedWorkQueue |
| Excutors.newSingleThreadPool(int) |                一池一个线程，一个任务一个线程                |
| Excutors.newCachedThreadPool(int) | 一池不定数量的线程，适用于短期异步小任务或者或者负载较轻的任务 |

ThreadPoolExecutor：最好不用Executors去创建，而是通过ThreadPoolExecutor的方式，为什么？

FixedThreadPool和CachedThreadPool允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。

CachedThreadPool允许创建的线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。

##### ThreadPoolExecutor

|  corePoolSize   |                   线程池中的常驻核心线程数                   |
| :-------------: | :----------------------------------------------------------: |
| maximumPoolSize |   线程池中能够容纳同时指向的**最大线程数**，必须大于等于1    |
|  keepAliveTime  |                 多余的空闲线程的**存活时间**                 |
|      unit       |               keepAliveTime**存活时间的单位**                |
|    workQueue    |          **任务队列**，存放已提交但是尚未执行的任务          |
|  threadFactory  |     表示生成线程池中工作线程的**线程工厂**，用于创建线程     |
|     handler     | **拒绝策略**，表示队列满了，并且工作线程大于等于线程池的最大线程数，拒绝请求执行的runnable的策略 |

###### 组塞队列的应用

<img src="https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210909214914.png" alt="image-20210909214914591" style="zoom:80%;" />

![image-20210909214942810](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210909214942.png)

###### 线程池的拒绝策略

|     AbortPolicy     |  直接抛出RejectedException   |
| :-----------------: | :--------------------------: |
|  CallerRunsPolicy   |         回退给调用者         |
| DiscardOldestPolicy | 丢弃阻塞队列中等待最久的任务 |
|    DiscardPolicy    |           直接丢弃           |

###### 线程池的执行顺序

- 在创建线程后，等待提交过来的任务请求

- 当调用executor()方法添加一个请求任务时，线程池会做出以下判断：

  - 若正在运行的线程数量小于corePoolSize，会立即创建核心线程运行该任务

  - 如果正在运行的线程大于corePoolSize，会将该任务放入阻塞队列中

  - 如果队列已满但是正在运行的线程数量小于maximumPoolSize，那麽还是要创建非核心线程立即运行这个任务

  - 如果等待队列已满，且在运行的线程数量大于或等于maximumPoolSize，那么线程池会启动饱和拒绝策略来执行

  - 当一个线程完成任务时，它会从等待队列中取出下一个任务来执行

  - 当一个线程无事可做超过一段时间后，线程会判断：

    如果当前运行的线程数大于corePoolSize，那么这个非核心线程就会被停掉，当线程的所有任务完成后，它会最终收缩到corePoolSize的大小

    阿里巴巴规范：

  ![img](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210913164133.png)

  ###### 生命周期管理

  线程池运行的状态，不是由用户显式设置的，而是伴随着线程池的运行，由内部来维护。，线程池内部使用一个变量维护两个值，运行状态和线程数量。在具体实现时，线程池将运行状态、线程数量两个关键参数的维护放在一起：用一个AtomicInteger类型的字段存，高三位保存runstate，低29位保存workerCount，两个变量互不干扰，不必为了维护两者的一致而占用锁资源，且使用位运算的方式相比于基本运算，速度会快一些。

  ###### ThreadPoolExecutor的运行状态

  |  运行状态  |                           状态描述                           |
  | :--------: | :----------------------------------------------------------: |
  |  RUNNING   |    能接受新提交的任务，并且也能处理阻塞队列中已保存的任务    |
  |  SHUTDOWN  | 关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务 |
  |    STOP    | 不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程 |
  |  TIDYING   |               所有任务都已经终止，WorkCount为0               |
  | TERMINATED |            在terminated()方法执行完之后进入该状态            |

  

![图3 线程池生命周期](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210913161456.png)

###### 线程调度

![图4 任务调度流程](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210913172257.png)

###### 线程池设计

CPU密集型：把核心数设置为核心数+1，原因：**即使当计算（CPU）密集型的线程偶尔由于页缺失故障或者其他原因而暂停时，这个“额外”的线程也能确保 CPU 的时钟周期不会被浪费**

IO操作型：



###### 手写系列

```java
package Concurrency;

import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.Map;

//手写生产者消费者模式
/*
* 1. 定义一个缓存队列，选择一个集合做缓存，缓存里面只做两件事情，存数据和取数据
* 2. 定义一个生产者线程生产数据，然后存缓存中
* 3. 定义一个消费者从缓存中取数据
* */
public class QueueTest<T> {
    //数据插入的下标
    private int putIndex = 0;
    //最大容量
    private int maxCount = 50;

    //缓冲区
    private LinkedHashMap<Integer,T> linkedHashMap = new LinkedHashMap<>();

    //往队列中添加数据
    public synchronized void put(T msg){
        //如果缓存的数据达到maxCount，阻塞
        if(linkedHashMap.size() == maxCount){
            try {
                wait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        else{
            //没有满，唤醒其他线程
            notifyAll();
        }
        linkedHashMap.put(putIndex,msg);
        System.out.println("生产一个产品，当前下标为："+putIndex+"   文本为："+msg+"   缓存长度："+linkedHashMap.size());
        //更新putIndex
        putIndex = (putIndex+1) >= maxCount ? (putIndex+1) % maxCount : putIndex+1;
    }
/**
 * 从阻塞队列中取数据
 */
public synchronized T get(){
         //阻塞队列为空，阻塞消费者
         if(linkedHashMap.size() == 0){
             try {
                 wait();
             } catch (InterruptedException e) {
                 e.printStackTrace();
             }
         }
         else{
             notifyAll();
         }
         //通过Iterator取数据，确保取出的数据是有序的
         Iterator iterator = linkedHashMap.entrySet().iterator();
         T t = null;
         if(iterator.hasNext()){
             Map.Entry<Integer,T> entry = (Map.Entry<Integer,T>) iterator.next();
             t = entry.getValue();
             int index = entry.getKey();
             linkedHashMap.remove(index);
             System.out.println("消费一个产品，当前商品下标为："+index+"   文本为："+ t +"   缓存长度为："+linkedHashMap.size());
         }
         return t;
     }
}
/**
 * 定义生产者线程
 */
class Provider extends Thread{
    private QueueTest queueTest;

    public Provider(QueueTest queueTest){
        this.queueTest = queueTest;
    }
     @Override
    public void run(){
        for(int i = 0;i<60;i++){
            queueTest.put(String.valueOf(i));
        }
     }
}

class Consumer extends Thread{

    private QueueTest queueTest;

    public Consumer(QueueTest queueTest) {
        this.queueTest = queueTest;
    }

    @Override
    public void run() {
        for (; ; ) {
            queueTest.get();
        }
    }
}
/**
 * 测试
 */
class ProviderConsumerTest {

    public static void main(String[] args) {
        QueueTest queueTest = new QueueTest();
        Provider provider = new Provider(queueTest);
        Consumer consumer = new Consumer(queueTest);
        provider.start();
        consumer.start();
    }
}
```



  ##### BIO/NIO/AIO

同步：同步调用中被调用者未处理完请求之前，调用不返回，调用者会一直等待结果的返回。

异步：异步调用中一方不需要等待另一方的结果返回，通过回调函数或者其它方式将结果返回。

内核如何进行IO交互？

1.网卡收到经过网线传来的网络数据，并将网络数据写到内存中。

2.当网卡把数据写入到内存后，网卡向cpu发出一个中断信号，操作系统便能得知有新数据到来，再通过网卡中断程序去处理数据。

3.将内存中的网络数据写入到对应socket的接收缓冲区中。

4.当接收缓冲区的数据写好之后，应用程序开始进行数据处理

- IO模型简介

BIO：同步并阻塞----一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不干任何事情就会造成不必要的线程开销。详细：由一个独立的Acceptor线程负责监听客户端的连接，接收到客户端连接之后为客户端连接创建一个新的线程处理请求消息，处理完成之后，返回应答消息给客户端，线程销毁。

![BIO](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210920204908.jpeg)

NIO：同步非阻塞----一个线程处理多个连接，客户端发送的连接请求会被注册到多路复用器上，多路复用器轮询到IO请求就会进行处理。





![NIO](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210920205154.jpeg)

AIO：异步非阻塞，有效的请求才启动线程，特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般用于连接较多且连接时间较长的应用。

使用场景：

BIO：连接数较小且固定

NIO：连接数较多且连接比较短

AIO：连接数目多且连接数比较长



###### BIO

![b9x162zhb3](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210928141657.png)

- accept，read都要阻塞
- 服务端对于每个请求都要创建一个独立的线程
- 并发数大，要创建大量的线程，系统资源占用大
- 建立连接后，如果当前线程没有数据可读，则线程就阻塞在read上，造成线程资源的浪费

###### NIO

NIO新增了Channel、Selector、Buffer等抽象概念，支持面向缓冲、基于通道的I/O操作的方法。

Java NIO 中的 Buffer 主要用于和 NIO 通道进行交互，数据是从通道读入到缓冲区的，然后从缓冲区中写入到通道中的

NIO提供了与传统BIO模型中的Socket和ServerSocket相对应的SocketChannel和ServerSocketChannel两种不同的套接字通道实现。

![图片](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210924161648.webp)

![ljbkaa6gdf](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210928141540.png)

- Selector选择器

也称多路复用器，用于检查一个或多个Channel（通道）的状态是否处于连接就绪、接受就绪、可读就绪、可写就绪。

利用selector可以实现单线程管理多个channels，相比BIO，Selector使用更少的线程就可以处理通道。

创建一个选择器：

```java
Selector selector = Selector.open();
```

注册一个通道到选择器中：

```java
//创建一个 TCP 套接字通道
SocketChannel channel = SocketChannel.open();
//调整通道为非阻塞模式
channel.configureBlocking(false);
//向选择器注册一个通道
SelectionKey key = channel.register(selector, SelectionKey.OP_READ);
```

register方法就是用于注册当前实例通道到指定的选择器。

当我们注册一个通道到选择器之后。就可以通过返回的SelectionKey实例监听该通道的各种事件。

```java
Set<SelectionKey> keys = selector.selectedKeys();
```

selectedKeys方法会返回选择器中注册成功的所有通道的SelectionKey实例集合，通过这个集合的SelectionKey实例，得到所有通道的事件就绪情况并进行相应的处理操作。

- 1个线程能处理多个连接，这个线程不停循环遍历就行了
- 单线程不停循环发起系统调用，一样会耗尽CPU资源
- NIO的瓶颈：由于需要不停的调用系统调用，每个连接都需要调系统调用询问是否有数据，很浪费资源，要是能明确地知道哪个连接有数据包过来，就不用一直遍历。

总结：

- 创建channel1和channel2，分别监听特定的端口

- 创建selector，并将channel1和channel2进行注册

- selector.select()一直阻塞，直到有至少一个通道准备就绪

- 轮询已经就绪的通道

- 根据事件类型做出相应的响应动作

  

###### AIO

AIO采取订阅-通知模式：即应用程序向操作系统注册IO监听，然后继续做自己的事情，当操作系统发生IO事件，并且准备好数据之后，再主动通知应用程序，触发相应的函数

![图片](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210924164544.webp)

实现：

Windows:IOCP

Linux:epoll

- 多路复用之select、poll、epoll

  文件描述符fd

  文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。

  文件描述符在形式上是一个非负整数。实际上，**它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符**,文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统

1. select

维护一个文件描述符数组，以此为基础，实现IO多路复用的功能，这个fd数组有长度限制。

select方法被调用。首先要将fd数组从用户空间拷贝到内核空间，直到有一个fd活跃，或者超时，方法返回。

select方法返回后，需要轮询fd数组，检查出发生IO事件的fd。

缺点：

- fd数组在用户空间和内核空间的频繁复制，效率低

- 单个进程可监控的fd数量有限
- 基于轮询实现，效率低

2. poll

poll也要进行数据结构的复制，依然是基于轮询来实现。但是使用的不是数组而是链表，所以从理论上讲，单个进程能监听的fd不再有数量的限制，但是轮询和数据结构的复制还是存在。

3. epoll

基于事件驱动实现，给每个fd注册一个回调函数，当fd对应的设备发生IO事件时，就会调用这个回调函数。把fd放到一个链表中，然后由客户端从该链表中取出一个个fd，达到O（1）的时间复杂度。

epoll操作的三个函数：

epoll_create

在内核中创建一个存放fd节点的红黑树，后续如果有新增的fd节点，都会注册到这个epoll红黑树上。

epoll_ctr

select和poll会一次性将监听的所有的fd都复制到内核中，而epoll在需要添加一个新的fd时，会调用epoll_ctr,给这个fd注册一个回调函数，然后将该节点注册到内核中的红黑树中。当该fd对应的设备活跃时，会调用该fd上的回调函数，将该节点存放在一个就绪链表中，不需要在内核和用户空间中来回复制。

epoll_wait

直接从就绪链表中取节点，解决了轮询的问题，时间复杂度变成O（1）

总结：

- 没有最大并发连接的限制
- 效率变高，因为基于事件驱动实现的，不会随着fd数量上升而效率下降
- 减少内存拷贝的次数

###### LT模式和ET模式

LT（水平触发）模式：当被监控的文件描述符上有可读写事件发生时，`epoll_wait()会一直通知用户程序去读写`，如果这个描述符是用户不关心的，它每次都返回通知用户，则会导致用户对于关心的描述符的处理效率降低。这种模式下`要注意多次读写的情况下，效率和资源利用率情况`。select和poll都是使用的水平触发模式。

ET（边缘触发）模式：当被监控的文件描述符上有可读写事件发生时，`epoll_wait()会通知用户程序去读写，它只会通知用户进程一次`，这需要用户一次把内容读取完，相当于水平触发，效率更高。如果用户一次没有读完数据，epoll_wait()再次请求时，不会立即返回，`直到该文件描述符上出现第二次可读写事件时才会通知你`。这种模式下`读写数据要注意一次是否能读写完成`。

###### 总结

`Java BIO`：同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。

`Java NIO` ：同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。

`Java AIO(NIO.2)`：异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。

###### 已经有NIO包了，为什么还需要Netty？

NIO在轮询已就绪的通道和对事件相应的处理是在同一个线程中，当事件处理比较耗时甚至是阻塞时，整个流程就会阻塞。实际上NIO使用的是一种单Reactor单线程设计模式。

![从I/O多路复用到Netty，还要跨过Java NIO包](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210928150617.png)

这种模型在Reactor中负责监听端口、接收请求，如果是连接事件交给acceptor处理，如果是读写事件和业务处理就交给handle处理，但是始终都是只有一个线程执行所有的事情。

为了提高性能，可以将事件处理交给线程池，变成单Reactor多线程

![从I/O多路复用到Netty，还要跨过Java NIO包](https://cdn.jsdelivr.net/gh/nanxi1234/nanxi1234.github.io/image/2021/20210928150857.png)

好处使把业务处理从之前的单一线程中脱离了出来，换成线程池处理，Reactor线程只需要负责连接事件、读写事件，所有的业务都交给线程池。

但是会发现一个Reactor线程承担了所有的网络事件，例如监听和相应，高并发场景下单线程还是存在性能问题。

这个时候可以构建两个Reactor，主reactor单独监听Server Socket，accept新连接，然后建立的SocketChannel注册给指定的从Reactor，从Reactor再执行事件的读写、分发、把业务处理给worker线程池完成。

因为Netty对NIO做出来这些优化，因此他比NIO快。

