---
title: 计算机操作系统
---

[TOC]





### 虚拟化CPU

  操作系统将单个CPU转换成*看似*无限数量的CPU，从而使许多程序看似同时运行，这就是所谓的虚拟化CPU。

### 虚拟化内存

内存就是一个字节数组，要读取内存，必须指定一个地址，才能访问存储在那里的数据。程序运行时，访问内存，程序将所有的数据结构和指令保存在内存里。通过从内存里读指令，再利用指令访问数据结构。每个进程访问自己的私有虚拟地址空间，操作系统以某种方式映射到机器的物理内存上，一个正在运行的程序中的内存引用不会影响到其他进程的地址空间。对于正在运行的程序，它完全拥有自己的物理内存，但实际上，物理内存是操作系统管理的共享资源。

### 时分共享技术

  通过让一个进程只运行一个时间片，然后切换到其他进程，操作系统提供了存在多个虚拟CPU的假象。
​	
​		  潜在的开销就是性能损失，因为如果CPU必须共享，每个进程的运行就会慢一些。
​	

通过允许资源由一个实体使用一小段时间，然后由另一个实体使用一小段时间，如此下去，所谓的资源(例如，CPU、内存、磁盘或则或网络链接)可以被许多人共享

  空分技术：资源在空间上被划分给需要使用它的人

## 进程

  一个进程就是一个正在执行的程序。在任何时刻，我们都可以清点它在执行过程中访问或影响的系统的不同部分，从而概括一个进程

### 进程的机器状态

​	定义：程序在**运行时**可以**读取**或**更新**的内容。

​	机器状态的组成部分：

- 内存：指令存在内存中。正在运行的程序读取和写入的数据也在内存中。因此进程可以访问的内存是该进程的一部分
- 寄存器：许多指令明确的读取或则更新寄存器，例如，程序计数器(PC)告诉我们程序即将执行哪个指令；类似的，栈指针和相关的帧指针用于管理函数参数栈，局部变量和返回地址。

### 进程创建

- 将代码和所有的静态数据(*例如初始化变量*)加载到内存中(*需要操作系统从磁盘中读取这些字节，并把他放在内存的某处*)，加载到进程的地址空间中。

- 创建和初始化栈以及执行与I/O设置相关的其他工作。

- 启动程序，在入口处运行，即main()，通过跳转到main()例程，OS将CPU的控制权交给新创建的进程，程序开始执行。

### 进程状态

-  运行
-  就绪
-  阻塞
                               
                           

<img src="https://cdn.jsdelivr.net/gh/nanxi1234/picture//2020/20201113180108.png" alt="09297314c4fd0855ef0a3aa14987314" style="zoom:67%;" />

​	从就绪到运行意味着该进程已经被调度，从运行转移到就绪意味着该进程已经取消调度。一旦进程被阻塞，OS将保持进程的这种状态，直到发生某种事件(例如，I/O完成)，此时，进程再次转入就绪状态

 例如：从磁盘读取数据或等待网络数据包时，进程会被阻塞。OS发现进程0不使用CPU并开始运行进程1。当进程1运行时，I/O完成(系统决定切不切回进程0)，将进程0移回就绪状态，最后，进程1结束，进程0运行，然后完成。

##### 上下文切换

对于停止的进程，寄存器上下文将保存其寄存器的内容，当一个进程停止时，它的寄存器将被保存到这个内存位置，通过恢复这些寄存器，操作系统可以恢复这些进程。

### 进程API

- fork()系统调用：用于创建新进程

- wait()系统调用：有时候我们需要一个进程在另一个进程之后运行，这时wait()就可以起作用，例如父进程延迟自己的执行，直到子进程执行完毕，当它结束时，wait()才返回执行父进程。

- exec()系统调用：这个系统调用可以让子进程执行与父进程不同的进程。

  ```c
  char *myargs[3];
  myargs[0]=strdup("wc");//program:"wc"(word count)
  mygrgs[1]=strup("p3.c");//argument:file to count
  myargs[2]=NULL;//marks end of array
  execpv(myargs[0],myargs);//runs word count 
  //进程调用execvp()来运行字符计数程序wc
  ```
	exec()会从可执行程序中加载代码和静态数据，并用它覆写自己的代码段(以及静态数据），堆、栈及其及其他内存空间也会被初始化。然后操作系统就执行该程序，将参数通过argv传递给该进程。因此，它没有创建新进程，而是直接将当前运行的程序替换为不同的运行程序。
	
	这样设计API的原因：在fork()之后exec()之前，可以在运行新程序之前改变环境。
	
	应用：shell命令行工具：向它输入一个命令（一个可执行程序的名称及需要的参数），shell可以在文件系统中找到这个可执行程序，调用fork()，创建新进程，并调用exec()的某个变体来执行这个可执行程序。

## 机制：受限直接运行

- 时分共享：为了虚拟化CPU，操作系统要以某种方式让许多任务共享物理CPU，让他们看起来像是在同时运行：运行一个进程一段时间，然后运行另外一个进程，如此轮换，实现虚拟化。
- 虚拟化机制的一些挑战：
  1. 性能：如何在不增加系统开销的情况下实现虚拟化
  2. 控制权：如何有效地运行进程，同时保留对CPU的控制？
### 受限直接执行
 	 只需要在CPU上运行程序即可。因此当OS希望启动程序时，它会在进程列表中为其创建一个进程条目，为其分配一些内存，将程序代码(从磁盘)加载到内存中，找到入口点，跳转到那里，开始运行用户的代码。

存在的问题：

- 操作系统如何确保程序不做任何我们不希望他做的事（用户模式和内核模式）

- 如何切换进程，实现CPU的时分共享（）


  解决方法：

  1. 用户模式和内核模式

    执行系统调用的过程：
    用户模式->执行陷阱指令->内核模式->陷阱返回指令->用户模式



  2. 时钟中断
          	时时钟设备可以编程为每隔几毫秒产生一次中断。产生中断时，当前正在运行的进程停止，操作系统中预先配置的中断处理程序会运行，操作系统重新获得CPU的控制权，因此他可以做他想做的事：停止当前进程，并启动另一进程。


  3. 上下文切换
           操作系统要做的就是为当前正在执行的进程保留一些寄存器的值，并为即将执行的进程恢复一些寄存器的值
         
     陷阱如何知道在OS内运行哪些代码？
		通过在启动时设置陷阱表来实现。当机器启动时，他在内核模式下执行，因此可以根据需要自由配置机器硬件。操作系统要做的第一件事，就是告诉硬件在发生异常时需要运行哪些代码。
	
	​    
### 总结
 	LDE的基本思路：让你想运行的程序在CPU上运行，首先设置好硬件，以便在没有操作系统帮助的情况下限制进程可以执行的操作

## 进程调度

​	为什么需要进程调度？进程调度解决的是什么问题？
​		进程调度回答的是：在特定的时间应该运行哪个进程的问题。

- 工作负载假设：
  一些与系统中运行的进程有关的假设
- 调度指标：
  周转时间：完成时间-到达时间、响应时间：首次运行-到达时间
### 多级反馈队列(Multi-level Feedback Queue)

​		MLFQ中有许多独立的队列，每个队列都有不同的优先级。任何时刻，一个工作只能存在与一个队列中，MLFQ总是先执行优先级高的工作。每个队列中可能有许多个工作，因此具有相同的优先级，这时采用轮转调度。MLFQ调度策略根据观察到的行为调整他的优先级。

MLFQ规则：

- 如果A的优先级>B的优先级，运行A(不运行B)
- 若相等则轮转运行A和B
- 工作进入系统时，放在最高优先级(最上层队列)
- 一旦工作用完了其在某一层的时间配额，就降低其优先级 (防止一个进程不断地在时间片用完之前主动释放CPU从而独占CPU)
- 经过一段时间S，就将系统中的所有工作重新加入最高优先级队列 (防止长工作被饿死)

关注进程的一贯表现。然后区别对待。

### 其他一些简单的进程调度算法

- 先进先出(FIFO)：先到的先执行
- 最短任务优先(SJF)：用时短的任务先做（由于工作是随时到达的，因此，可能一个比较长的工作先到达，这样会浪费时间）
- 最短完成时间优先(STCF)：，每当新工作进入系统时，确定剩余工作和新工作中，谁的剩余时间最少就执行谁（周转时间最优，但是响应时间不行）
- 轮转(RR)：RR在一个时间片内循环执行所有任务直至全部完成(优点：响应时间短，但是周转时间很长)

### 多处理器调度

- 如何解决缓存一致性问题？

  每个缓存都通过监听链接所有缓存和内存的总线，来发现内存访问，如果cpu发现对它放在缓存中的数据更新，会删除或更新本地副本。

- 缓存亲密度

  尽量将进程保持在同一个CPU上（在相同的cpu上运行时，由于缓存中的数据执行的更快，在不同的cpu上执行时，需要重新加载数据导致变慢）

- 单队列调度（SQMS）：将所有的工作放入一个单独的队列中（由于数据共享会带来并发的问题，加锁浪费时间，并且要考虑缓存亲密度的问题）

- 多队列调度（MQMS）：由于每个cpu都有自己的调度队列，每个cpu之间的调度之间相互独立，避免了单队列的方式由于数据共享和同步带来的问题。

存在的问题：

负载不均：让工作迁移，跨cpu迁移，可以真正实现负载均衡。如何实现？工作量较少的队列不定期检查其他队列是不是比自己工作多，如果是，就窃取一个或多个工作，实现负载均衡。问题：要确定好检查间隔，太短浪费时间，太长了，又解决不好负载不均。



# 虚拟化内存

操作系统在专门硬件的帮助下，通过每一个虚拟内存的索引，将其转换为物理地址。物理内存根据所得到的物理地址去获取所需的信息。

##### 分段与分页的区别

给地址空间中的每一个逻辑段一对基址和界限寄存器对，一个段是地址空间中的一个连续定长的区域，在典型的地址空间中有三个逻辑不同的段，代码，栈和堆。分段机制使得操作系统能将不同的段放到不同的物理内存区域，从而避免了虚拟地址空间中未使用部分占用物理内存。

分段带来的问题：

- 操作系统在上下文切换时，各个段寄存器中的内容必须保存和恢复，每个进程都有自己独立的虚拟地址空间，操作系统必须在进程运行前，确保寄存器被正确地赋值。
- 管理物理内存的空闲空间：新的地址空间被创建时，操作系统需要在物理内存中为它的段找到空间，随着时间的推移，物理内存会很快充满许多空闲空间的小洞，因此很难分配给新的段，或扩大已有的段，这叫做外部碎片。（内部碎片：分配程序给出的内存块超出了请求的大小，超出的空间称为内部碎片，浪费的空间在已分配单元的内部）。
- 分段不足以支持更一般化的稀疏地址空间，如果有一个很大但是很稀疏的堆都在一个逻辑段之中，整个堆还是必须全部加载到内存中。

带来的额外好处：

代码共享：由于代码放在独立的段之中，这样段就可以被多个运行的程序共享。





##### 空闲空间管理

在堆上进行空闲空间管理的数据结构称为空闲列表

底层机制：分割与合并

基本策略：

- 最优匹配：遍历整个空闲列表，找到大于或等于请求大小的最小空闲块，这样做能够避免空间浪费，但是需要付出时间上的代价。
- 最差匹配：与最优匹配相反，会导致过量的碎片，同时还有时间上的成本。
- 首次匹配：找到一个足够大的块，将请求的空间返回给用户，它只需找到一个大于请求空间的数，因此较快，缺点在于每次匹配都要重头开始，会导致空闲列表的开头有很多小块。
- 下次匹配：每一次都从上一次查找结束的位置开始查找，这样有利于将对空闲空间的查找动作扩散到整个列表中去，避免了对列表开头的频繁切割。

##### 分页

分页将空间分割为固定长度的分片











